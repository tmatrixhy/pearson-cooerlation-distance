{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load dependencies / mount drive\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv \n",
    "import json\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dest_1_sm = 'CF_docl_matrix.json'\n",
    "dest_2_bg = 'AB_docl_matrix.json'\n",
    "\n",
    "# Load Datasets to begin work.\n",
    "\n",
    "with open(dest_1_sm) as sm_file:\n",
    "  small_data = json.load(sm_file)\n",
    "\n",
    "with open(dest_2_bg) as bg_file:\n",
    "  big_data = json.load(bg_file)\n",
    "\n",
    "# select which dataset to use\n",
    "data = big_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total # of IDs:     9045\n",
      "Feature Value Min:  9045\n",
      "Feature Value Max:  45453\n"
     ]
    }
   ],
   "source": [
    "id_list = [] # List of Anonymized Twitter ID's\n",
    "data_set = {} # Set version of original data\n",
    "max_feature = float('-inf') # maximum value in feature column\n",
    "min_feature = float('inf') # minimum value in feature column - Might not  need this\n",
    "\n",
    "# O(n * m)\n",
    "for key in data: #O(n)\n",
    "  id_list.append(key) #O(1)\n",
    "  data_set[key] = set(data[key]) #O(m)\n",
    "  max_feature = max(max_feature, max(data_set[key])) #O(m)\n",
    "  min_feature = min(min_feature, min(data_set[key])) #O(m)\n",
    "\n",
    "# Since min_feature == 0, add 1 to max_feature\n",
    "max_feature+= 1\n",
    "\n",
    "print(\"Total # of IDs:    \", len(id_list))\n",
    "print(\"Feature Value Min: \", min_feature)\n",
    "print(\"Feature Value Max: \", max_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_r_value(set_a, set_b, max_feature):\n",
    "  # length of set_a is the same as the sum of all 'x'\n",
    "  sig_x = len(set_a)\n",
    "\n",
    "  # mean of all set_a values = sum of all x / total feature count\n",
    "  avg_x = sig_x / max_feature\n",
    "\n",
    "  # do same calculations for 'y'\n",
    "  sig_y = len(set_b)\n",
    "  avg_y = sig_y / max_feature\n",
    "\n",
    "  # Senario A: x = 1, y = 1  \n",
    "  # -- Intersection Time Complexity (Avg): O(min(len(a), len(b)))\n",
    "  sen_a = set_a.intersection(set_b) \n",
    "  numerator = len(sen_a) * ((1-avg_x) * (1-avg_y))\n",
    "  denom_x = len(sen_a) * ((1-avg_x)**2)\n",
    "  denom_y = len(sen_a) * ((1-avg_y)**2)\n",
    "\n",
    "  # Senario B: x = 1, y = 0  \n",
    "  # -- Difference Time Complexity (Avg): O(len(a))\n",
    "  sen_b = set_a.difference(set_b)  \n",
    "  numerator += len(sen_b) * ((1-avg_x) * (-avg_y))\n",
    "  denom_x += len(sen_b) * ((1-avg_x)**2)\n",
    "  denom_y += len(sen_b) * ((-avg_y)**2)\n",
    "\n",
    "  # Senario C: x = 0, y = 1  \n",
    "  # -- Difference Time Complexity (Avg): O(len(b))\n",
    "  sen_c = set_b.difference(set_a)\n",
    "  numerator += len(sen_c) * ((-avg_x) * (1-avg_y))\n",
    "  denom_x += len(sen_c) * ((-avg_x)**2)\n",
    "  denom_y += len(sen_c) * ((1-avg_y)**2)\n",
    "\n",
    "  # Senario D: x = 0, y = 0  \n",
    "  # -- Union Time Complexity (Avg): O(len(a) + len(b))\n",
    "  sen_d = (max_feature - len(set_a.union(set_b)))\n",
    "  numerator += sen_d * (avg_x * avg_y)\n",
    "  denom_x += sen_d * (avg_x**2)\n",
    "  denom_y += sen_d * (avg_y**2)\n",
    "\n",
    "  denominator = math.sqrt(denom_x * denom_y)\n",
    "\n",
    "  return 1 - (numerator / denominator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to Execute (ms):  5581196.880578995\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Normal Execution\n",
    "'''\n",
    "def create_PCC_matrix(max_feature, id_list, data_set):\n",
    "  start_time = time.time()\n",
    "  adjacency_matrix = np.zeros((len(id_list), len(id_list)))\n",
    "  adjacency_list = []\n",
    "\n",
    "  for x in range(0,len(id_list)):\n",
    "    for y in range(x+1, len(id_list)):\n",
    "      adjacency_matrix[x][y] = calculate_r_value(data_set[id_list[x]], data_set[id_list[y]], max_feature)\n",
    "      adjacency_list.append([id_list[x], id_list[y], adjacency_matrix[x][y]])\n",
    "\n",
    "  print(\"Time to Execute (ms): \", str((time.time() - start_time)*1000))\n",
    "  return adjacency_list , adjacency_matrix\n",
    "\n",
    "adjacency_list, adjacency_matrix = create_PCC_matrix(max_feature, id_list, data_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('adj_matrix.csv', 'w') as fh:\n",
    "    writer = csv.writer(fh, delimiter=',')\n",
    "    writer.writerow(id_list)\n",
    "    for x in adjacency_matrix:\n",
    "        writer.writerow(x)\n",
    "\n",
    "csv_columns = ['id_1','id_2', 'PCD']\n",
    "with open('adj_list.csv', 'w') as fh:\n",
    "    writer = csv.writer(fh, delimiter=',')\n",
    "    writer.writerow(csv_columns)\n",
    "    for x in adjacency_list:\n",
    "        writer.writerow(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
