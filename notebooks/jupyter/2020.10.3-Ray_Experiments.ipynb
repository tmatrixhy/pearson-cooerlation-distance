{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load dependencies / mount drive\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import glob\n",
    "import csv \n",
    "import json\n",
    "import scipy\n",
    "import math\n",
    "import time\n",
    "import ray\n",
    "import psutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-10-03 23:10:53,450\tINFO services.py:1166 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'node_ip_address': '192.168.1.196',\n",
       " 'raylet_ip_address': '192.168.1.196',\n",
       " 'redis_address': '192.168.1.196:6379',\n",
       " 'object_store_address': '/tmp/ray/session_2020-10-03_23-10-52_944244_16250/sockets/plasma_store',\n",
       " 'raylet_socket_name': '/tmp/ray/session_2020-10-03_23-10-52_944244_16250/sockets/raylet',\n",
       " 'webui_url': '127.0.0.1:8265',\n",
       " 'session_dir': '/tmp/ray/session_2020-10-03_23-10-52_944244_16250',\n",
       " 'metrics_export_port': 39920}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ray.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dest_1_sm = 'CF_docl_matrix.json'\n",
    "dest_2_bg = 'AB_docl_matrix.json'\n",
    "\n",
    "# Load Datasets to begin work.\n",
    "\n",
    "with open(dest_1_sm) as sm_file:\n",
    "  small_data = json.load(sm_file)\n",
    "\n",
    "with open(dest_2_bg) as bg_file:\n",
    "  big_data = json.load(bg_file)\n",
    "\n",
    "# select which dataset to use\n",
    "data = small_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total # of IDs:     1000\n",
      "Feature Value Min:  0\n",
      "Feature Value Max:  459316\n"
     ]
    }
   ],
   "source": [
    "id_list = [] # List of Anonymized Twitter ID's\n",
    "data_set = {} # Set version of original data\n",
    "max_feature = float('-inf') # maximum value in feature column\n",
    "min_feature = float('inf') # minimum value in feature column - Might not  need this\n",
    "\n",
    "# O(n * m)\n",
    "for key in data: #O(n)\n",
    "  id_list.append(key) #O(1)\n",
    "  data_set[key] = set(data[key]) #O(m)\n",
    "  max_feature = max(max_feature, max(data_set[key])) #O(m)\n",
    "  min_feature = min(min_feature, min(data_set[key])) #O(m)\n",
    "\n",
    "# Since min_feature == 0, add 1 to max_feature\n",
    "max_feature+= 1\n",
    "\n",
    "#sort id_list\n",
    "id_list.sort()\n",
    "\n",
    "print(\"Total # of IDs:    \", len(id_list))\n",
    "print(\"Feature Value Min: \", min_feature)\n",
    "print(\"Feature Value Max: \", max_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "def calculate_r_value(set_a, set_b, max_feature):\n",
    "  # length of set_a is the same as the sum of all 'x'\n",
    "  sig_x = len(set_a)\n",
    "\n",
    "  # mean of all set_a values = sum of all x / total feature count\n",
    "  avg_x = sig_x / max_feature\n",
    "\n",
    "  # do same calculations for 'y'\n",
    "  sig_y = len(set_b)\n",
    "  avg_y = sig_y / max_feature\n",
    "\n",
    "  # Senario A: x = 1, y = 1  \n",
    "  # -- Intersection Time Complexity (Avg): O(min(len(a), len(b)))\n",
    "  sen_a = set_a.intersection(set_b) \n",
    "  numerator = len(sen_a) * ((1-avg_x) * (1-avg_y))\n",
    "  denom_x = len(sen_a) * ((1-avg_x)**2)\n",
    "  denom_y = len(sen_a) * ((1-avg_y)**2)\n",
    "\n",
    "  # Senario B: x = 1, y = 0  \n",
    "  # -- Difference Time Complexity (Avg): O(len(a))\n",
    "  sen_b = set_a.difference(set_b)  \n",
    "  numerator += len(sen_b) * ((1-avg_x) * (-avg_y))\n",
    "  denom_x += len(sen_b) * ((1-avg_x)**2)\n",
    "  denom_y += len(sen_b) * ((-avg_y)**2)\n",
    "\n",
    "  # Senario C: x = 0, y = 1  \n",
    "  # -- Difference Time Complexity (Avg): O(len(b))\n",
    "  sen_c = set_b.difference(set_a)\n",
    "  numerator += len(sen_c) * ((-avg_x) * (1-avg_y))\n",
    "  denom_x += len(sen_c) * ((-avg_x)**2)\n",
    "  denom_y += len(sen_c) * ((1-avg_y)**2)\n",
    "\n",
    "  # Senario D: x = 0, y = 0  \n",
    "  # -- Union Time Complexity (Avg): O(len(a) + len(b))\n",
    "  sen_d = (max_feature - len(set_a.union(set_b)))\n",
    "  numerator += sen_d * (avg_x * avg_y)\n",
    "  denom_x += sen_d * (avg_x**2)\n",
    "  denom_y += sen_d * (avg_y**2)\n",
    "\n",
    "  denominator = math.sqrt(denom_x * denom_y)\n",
    "\n",
    "  return 1 - (numerator / denominator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to Execute (ms):  240982.79237747192\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Execution using Ray library for parallelized processing.\n",
    "This ended up being slower than just running serially. \n",
    "Didn't have time to debug.\n",
    "'''\n",
    "\n",
    "\n",
    "def create_PCC_matrix(max_feature, id_list, data_set):\n",
    "  start_time = time.time()\n",
    "  adjacency_matrix = np.zeros((len(id_list), len(id_list)))\n",
    "  adjacency_list = {}\n",
    "\n",
    "  ray_list = []\n",
    "  \n",
    "  for x in range(0,len(id_list)):\n",
    "    for y in range(x+1, len(id_list)):\n",
    "      r_val = calculate_r_value.remote(data_set[id_list[x]], data_set[id_list[y]], max_feature)\n",
    "      \n",
    "      ray_list.append(r_val)\n",
    "\n",
    "  ray_list = ray.get(ray_list)\n",
    "\n",
    "  counter = 0\n",
    "  for x in range(0,len(id_list)):\n",
    "    for y in range(x+1, len(id_list)):\n",
    "      adjacency_matrix[x][y] = ray_list[counter]\n",
    "      adjacency_list[(id_list[x], id_list[y])] = ray_list[counter]\n",
    "      counter+=1\n",
    "  print(\"Time to Execute (ms): \", str((time.time() - start_time)*1000))\n",
    "  return adjacency_list , adjacency_matrix\n",
    "\n",
    "adjacency_list, adjacency_matrix = create_PCC_matrix(max_feature, id_list, data_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to Execute (ms):  58316.06960296631\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Normal Execution\n",
    "'''\n",
    "def create_PCC_matrix(max_feature, id_list, data_set):\n",
    "  start_time = time.time()\n",
    "  adjacency_matrix = np.zeros((len(id_list), len(id_list)))\n",
    "  adjacency_list = []\n",
    "\n",
    "  for x in range(0,len(id_list)):\n",
    "    for y in range(x+1, len(id_list)):\n",
    "      adjacency_matrix[x][y] = calculate_r_value(data_set[id_list[x]], data_set[id_list[y]], max_feature)\n",
    "      adjacency_list.append([id_list[x], id_list[y], adjacency_matrix[x][y]])\n",
    "\n",
    "  print(\"Time to Execute (ms): \", str((time.time() - start_time)*1000))\n",
    "  return adjacency_list , adjacency_matrix\n",
    "\n",
    "adjacency_list, adjacency_matrix = create_PCC_matrix(max_feature, id_list, data_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('adj_matrix.csv', 'w') as fh:\n",
    "    writer = csv.writer(fh, delimiter=',')\n",
    "    writer.writerow(id_list)\n",
    "    for x in adjacency_matrix:\n",
    "        writer.writerow(x)\n",
    "\n",
    "csv_columns = ['id_1','id_2', 'PCD']\n",
    "with open('adj_list.csv', 'w') as fh:\n",
    "    writer = csv.writer(fh, delimiter=',')\n",
    "    writer.writerow(csv_columns)\n",
    "    for x in adjacency_list:\n",
    "        writer.writerow(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
